- hosts: master
  become: yes
  gather_facts: yes

  tasks:

    # --------------------------------------------------
    # Check if cluster already initialized
    # --------------------------------------------------
    - name: Check if kube-apiserver manifest exists
      stat:
        path: /etc/kubernetes/manifests/kube-apiserver.yaml
      register: apiserver_manifest

    # --------------------------------------------------
    # Initialize Kubernetes cluster (ONLY ONCE)
    # --------------------------------------------------
    - name: Initialize Kubernetes cluster
      command: kubeadm init --pod-network-cidr=10.244.0.0/16
      when: not apiserver_manifest.stat.exists
      register: kubeadm_init
      changed_when: kubeadm_init.rc == 0

    # --------------------------------------------------
    # Ensure kubeconfig directory
    # --------------------------------------------------
    - name: Ensure kubeconfig directory exists
      file:
        path: /home/ubuntu/.kube
        state: directory
        owner: ubuntu
        group: ubuntu
        mode: '0755'

    # --------------------------------------------------
    # Copy admin kubeconfig
    # --------------------------------------------------
    - name: Copy admin kubeconfig
      copy:
        src: /etc/kubernetes/admin.conf
        dest: /home/ubuntu/.kube/config
        owner: ubuntu
        group: ubuntu
        mode: '0644'
        remote_src: yes

    # --------------------------------------------------
    # Wait for kube-apiserver health (LOW LEVEL CHECK)
    # --------------------------------------------------
    - name: Wait for kube-apiserver to be healthy
      shell: curl -k https://127.0.0.1:6443/healthz
      register: api_health
      retries: 20
      delay: 15
      until: api_health.stdout == "ok"

    # --------------------------------------------------
    # Verify kubectl access (SAFE CHECK)
    # --------------------------------------------------
    - name: Verify kubectl access
      shell: kubectl get nodes
      environment:
        KUBECONFIG: /etc/kubernetes/admin.conf
      register: kubectl_check
      retries: 10
      delay: 10
      until: kubectl_check.rc == 0

    # --------------------------------------------------
    # Install Helm (idempotent)
    # --------------------------------------------------
    - name: Check if Helm is installed
      stat:
        path: /usr/local/bin/helm
      register: helm_bin

    - name: Install Helm
      shell: curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
      when: not helm_bin.stat.exists

    # ==================================================
    # ðŸ”¹ NEW TASKS â€“ AWS LOAD BALANCER CONTROLLER SETUP
    # ==================================================

    - name: Add EKS Helm repo
      become_user: ubuntu
      shell: |
        helm repo add eks https://aws.github.io/eks-charts
        helm repo update

    - name: Install cert-manager
      become_user: ubuntu
      shell: |
        kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.3/cert-manager.yaml

    - name: Wait for cert-manager pods to be ready
      become_user: ubuntu
      shell: |
        kubectl wait --for=condition=Ready pods --all -n cert-manager --timeout=300s

    - name: Install AWS Load Balancer Controller
      become_user: ubuntu
      shell: |
        helm upgrade --install aws-load-balancer-controller eks/aws-load-balancer-controller \
          -n kube-system \
          --set clusterName={{ cluster_name }} \
          --set region={{ region }} \
          --set vpcId={{ vpc_id }} \
          --set serviceAccount.create=true

    # --------------------------------------------------
    # Install Flannel CNI (ONLY ONCE)
    # --------------------------------------------------
    - name: Check if Flannel is already installed
      stat:
        path: /etc/cni/net.d/10-flannel.conflist
      register: flannel_conf

    - name: Install Flannel CNI
      command: kubectl apply -f https://raw.githubusercontent.com/flannel-io/flannel/master/Documentation/kube-flannel.yml
      environment:
        KUBECONFIG: /etc/kubernetes/admin.conf
      when: not flannel_conf.stat.exists

    # --------------------------------------------------
    # Wait for node to become Ready (CNI required)
    # --------------------------------------------------
    - name: Wait for master node to be Ready
      become_user: ubuntu
      shell: kubectl get nodes --no-headers | grep -v NotReady
      retries: 20
      delay: 15
      register: node_ready
      until: node_ready.rc == 0
      changed_when: false

    # --------------------------------------------------
    # Check if ingress-nginx namespace exists
    # --------------------------------------------------
    - name: Check if ingress-nginx namespace exists
      become_user: ubuntu
      command: kubectl get ns ingress-nginx
      register: ingress_ns
      failed_when: false
      changed_when: false

    # --------------------------------------------------
    # Install NGINX Ingress Controller (ONLY ONCE)
    # --------------------------------------------------
    - name: Install NGINX Ingress Controller
      become_user: ubuntu
      shell: kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/main/deploy/static/provider/cloud/deploy.yaml
      when: ingress_ns.rc != 0

    - name: Scale ingress controller
      become_user: ubuntu
      shell: kubectl scale deploy ingress-nginx-controller -n ingress-nginx --replicas=2

    # --------------------------------------------------
    # Generate join command (SAFE & REUSABLE)
    # --------------------------------------------------
    - name: Check if join command already exists
      stat:
        path: /tmp/kubeadm_join.sh
      register: join_script

    - name: Generate join command
      command: kubeadm token create --print-join-command
      register: join_cmd
      when: not join_script.stat.exists

    - name: Save join command
      copy:
        content: "{{ join_cmd.stdout }}"
        dest: /tmp/kubeadm_join.sh
        mode: '0755'
      when: not join_script.stat.exists