- hosts: master
  become: yes
  gather_facts: yes

  vars:
    kubeconfig: /etc/kubernetes/admin.conf

  tasks:

  # ==================================================
  # CLUSTER GUARD (FAIL FAST)
  # ==================================================
  - name: Verify Kubernetes API is reachable
    become_user: ubuntu
    shell: kubectl get nodes
    register: k8s_health
    retries: 10
    delay: 10
    until: k8s_health.rc == 0
    changed_when: false

  # ==================================================
  # CERT-MANAGER (GUARDED)
  # ==================================================

  - name: Check if cert-manager namespace exists
    become_user: ubuntu
    shell: kubectl get ns cert-manager
    register: cert_ns
    failed_when: false
    changed_when: false

  - name: Install cert-manager (only if missing)
    become_user: ubuntu
    shell: |
      kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.13.3/cert-manager.yaml
    when: cert_ns.rc != 0

  - name: Check if cert-manager controller is already ready
    become_user: ubuntu
    shell: |
      kubectl get deployment cert-manager -n cert-manager \
      -o jsonpath='{.status.readyReplicas}'
    register: cert_ready
    failed_when: false
    changed_when: false

  - name: Wait for cert-manager deployments
    become_user: ubuntu
    shell: |
      kubectl rollout status deployment/cert-manager -n cert-manager --timeout=5m
      kubectl rollout status deployment/cert-manager-webhook -n cert-manager --timeout=5m
      kubectl rollout status deployment/cert-manager-cainjector -n cert-manager --timeout=5m
    when: cert_ready.stdout | int < 1

  # ==================================================
  # HELM REPO (GUARDED)
  # ==================================================

  - name: Check if EKS Helm repo exists
    become_user: ubuntu
    shell: helm repo list | grep eks
    register: eks_repo
    failed_when: false
    changed_when: false

  - name: Add EKS Helm repo
    become_user: ubuntu
    shell: |
      helm repo add eks https://aws.github.io/eks-charts
      helm repo update
    when: eks_repo.rc != 0

  # ==================================================
  # AWS LOAD BALANCER CONTROLLER (GUARDED)
  # ==================================================

  - name: Check AWS Load Balancer Controller deployment
    become_user: ubuntu
    shell: kubectl get deployment aws-load-balancer-controller -n kube-system
    register: alb_dep
    failed_when: false
    changed_when: false

  - name: Install AWS Load Balancer Controller
    become_user: ubuntu
    shell: |
      helm upgrade --install aws-load-balancer-controller eks/aws-load-balancer-controller \
        -n kube-system \
        --set clusterName={{ cluster_name }} \
        --set region={{ region }} \
        --set vpcId={{ vpc_id }} \
        --set serviceAccount.create=true \
        --set serviceAccount.name=aws-load-balancer-controller
    when: alb_dep.rc != 0

  - name: Wait for AWS Load Balancer Controller deployment
    become_user: ubuntu
    shell: |
      kubectl rollout status deployment/aws-load-balancer-controller \
        -n kube-system --timeout=5m

  # ==================================================
  # PATCH WORKER NODES WITH PROVIDER ID (INSTANCE MODE)
  # ==================================================

  - name: Get EC2 instance-id from workers
    become_user: ubuntu
    delegate_to: "{{ item }}"
    uri:
      url: http://169.254.169.254/latest/meta-data/instance-id
      return_content: yes
    register: ec2_instance_ids
    loop: "{{ groups['workers'] }}"
    changed_when: false

  - name: Get EC2 availability zone from workers
    become_user: ubuntu
    delegate_to: "{{ item }}"
    uri:
      url: http://169.254.169.254/latest/meta-data/placement/availability-zone
      return_content: yes
    register: ec2_azs
    loop: "{{ groups['workers'] }}"
    changed_when: false

  - name: Patch providerID on Kubernetes worker nodes
    become_user: ubuntu
    loop: "{{ groups['workers'] }}"
    vars:
      idx: "{{ ansible_loop.index0 }}"
      worker_ip: "{{ hostvars[item].ansible_default_ipv4.address }}"
    shell: |
      NODE_NAME=$(kubectl get nodes -o wide | awk '$6 == "{{ worker_ip }}" {print $1}')
      CURRENT_PROVIDER=$(kubectl get node $NODE_NAME -o jsonpath='{.spec.providerID}')
      if [ -z "$CURRENT_PROVIDER" ]; then
        kubectl patch node $NODE_NAME \
        -p '{"spec":{"providerID":"aws:///{{ ec2_azs.results[idx].content }}/{{ ec2_instance_ids.results[idx].content }}"}}'
      fi
    environment:
      KUBECONFIG: "{{ kubeconfig }}"

  # ==================================================
  # RESTART AWS LOAD BALANCER CONTROLLER (RECONCILE)
  # ==================================================

  - name: Restart AWS Load Balancer Controller
    become_user: ubuntu
    shell: |
      kubectl rollout restart deployment aws-load-balancer-controller -n kube-system
    environment:
      KUBECONFIG: "{{ kubeconfig }}"